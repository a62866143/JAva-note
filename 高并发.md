# 高并发系统

​		本文主要研究高并发系统架构[1]的设计与实现[2]，主要包括系统的数据缓存[3]，负载均衡[4]，内容分发，数据库调优[5]等技术来降低服务器端的数据处理性能开销，以便提高服务器整体的承受访问的能力。高并发系统涉及到前端界面显示和数据录入，网络链路的数据传输和交互操作，后台数据处理，服务器调用和数据存储等多个环节。对这些环节需要进行细致的分析，掌握网站运行实现的技术细节从而优化系统结构来应对对应平台的高并发访问。高并发[6]系统架构由服务器等多种设备组合而成，这些设备在系统中不是简单的罗列便可满足我们的使用，需要对其采取特定的方法来提高服务器的负载能力。从具体方面，大致可分为七个点对系统的高并发性能进行提升。

具体化表现指标有：

响应时间（系统对请求处理的时间），

吞吐量（单位时间内处理的请求数量），

QPS（每秒响应查询请求数），

TPS（每秒响应事务请求数），

并发用户数（同时承载正常使用系统功能的用户数量）等。我们对系统高并发的优化程度可以在一定层面上来说就是增加上面这些参考指标的数值。

1. **系统集群化的部署以及负载均衡**  部署采用集群化多活部署，多台服务器保证服务的稳定性，若有一台服务器产生故障，其他服务器可以马上接管其任务，保证提供的服务可以正常运行；负载均衡一般都选择在linux的系统环境下部署Nginx，Nginx做反向代理，实现后端应用服务器的负载均衡，将请求均匀打到系统层，平衡各个操作单元的工作量，也使系统整体在资源尽可能完全使用上的情况下提高总的服务量。 

2. **数据库**的分库分表[7]，读写分离以及存储方面[8]的分布式数据库[9]以及分布式存储[10]  因为关系型数据库本身特点，单机存储容量、连接数、处理能力都有上限。所以当单表数据量达到一定的范围时，需要对其进行切分来减少数据库的负担，提高查询效率。
   1. 切割大致分为两类：垂直切割和水平切割。分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与"微服务治理"[11]的做法相似，每个微服务使用单独的一个数据库。而当垂直切割后数据量仍然较大，就需要进行水平切割。水平切割是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。但当库内分表只是解决了单一表数据量过大的问题，为了减轻Mysql数据库的压力，还可以额外采取分库分表来解决。
3. **缓存**方面，本地缓存，分布式缓存[12]和预缓存  本地缓存因为数据不需要网络传输，所以有更好的性能。在java编程中，常用的有HashMap 和 ConcurretHashMap，都是key-value的键值对数据结构。但是一般只适合缓存读数据。分布式缓存一般以集群化的方式拓展，所以支持大数据量存储。而且因为是独立部署的进程，所以具有良好的稳定性，不会受到其他因素影响。并且分布式一般都有备份机制，可以实现读写分离，可以解决高并发场景中的数据读写性能问题。分布式同时也提高了缓存数据的可用性，避免某个缓存节点宕机导致数据不可用问题。一般采用的技术为Redis[13]。而预缓存就是预先将页面的缓存加载好，便于用户下次访问该网页时刻直接访问缓存提高响应效率，优化用户体验。
4. **消息中间件**[14]：系统解耦，异步通讯  消息队列是消息中间件的一种实现方式，消息是指软件对象之间进行交互作用和通讯利用的一种方式。 中间件则是将信息与信息之间的联系践行一种存储或者管理的技术，这就是中间件技术。通过消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口，当应用发生变化时，可以独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。有些业务不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列当中，但并不立即处理它。待需要去处理时再去处理。
5. **微服务方面**[15]，对应用进行拆分，按业务拆分，分级部署以及应用资源隔离  微服务架构是一种架构概念，旨在通过将功能分解到各个离散的服务中以实现对解决方案的解耦。它的主要作用是将功能分解到离散的各个服务当中，从而降低系统的耦合性，并提供更加灵活的服务支持。且每个微服务可独立运行在自己的进程里，一系列独立运行的微服务共同构建起整个系统，每个服务为独立的业务开发，一个微服务只关注某个特定的功能。微服务之间可通过一些轻量的通信机制进行通信，且可以使用不同的语言与数据存储技术，部署方面又是全自动部署机制。
6. **并发，线程池**[16]内多线程的管理和并行处理任务方面  使用线程池可以减少线程反复的创建与降低资源消耗，并提高响应速度，也可以提高线程的可管理性。并行处理任务方面任务处理机仅仅负责处理和他建立对应关系的任务，而对单个处理机而已仅仅是一个串行的任务处理机，这样整个并发模型的构建具有很强的灵活性和稳定性。
7. **CDN**[17]，提升服务稳定性高，合理分配用户请求到最近的服务节点  CDN（[内容分发网络](https://baike.baidu.com/item/内容分发网络/4034265)）是构建在现有网络基础之上的智能虚拟网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率 。基本原理是使用各种缓存服务器，将这些服务器分布到用户访问频率更高一些的地区或网络中。使得用户访问网站时，利用全局负载技术将用户的访问指向距离最近的工作正常的缓存服务器上，由缓存服务器直接响应用户请求，提高响应效率。 



### Jmeter

压力测试

1.解释什么是jmeter?

　　jmeter是一款java开源工具，用于性能负载测试。它旨在分析和衡量web应用程序和各种服务的性能和负载功能行为。

2.说明jmeter的工作原理？

　　jmeter就像一群将请求发送到目标服务器的用户一样。它收集来自目标服务器的响应以及其他统计数据，这些统计数据通过图形或表格显示应用程序或服务器的性能。

3.说明可以在哪里使用函数和变量？

　　变量和函数可以写入任何测试组件的任何字段。

4.提到jmeter中的正则表达式是什么？

　　根据模式（patterns），使用正则表达式搜索和操作文本。jmeter可用于解释在整个jmeter测试计划中使用的正则表达式或模式的形式。

5.解释什么是采样器（Samplers）和线程组（Thread group）?

　　线程组：对于任何测试计划，线程组元件都是JMeter的开始部分。这是JMeter的重要元件，你可以在其中设置多个用户和时间来加载线程组中给出的所有用户。
　　采样器：采样器生成一个或多个采样结果；这些采样结果具有许多属性，例如经过时间、数据大小等。采样器允许JMeter通过采样器将特定类型的请求发送到服务器，线程组决定需要发出的请求类型。一些有用的采样器包括HTTP请求、FTP请求、JDBC请求等等。

 

6、使用JMeter构建的测试计划是否依赖于操作系统？
　　通常，测试计划以XML格式保存，因此与任何特定的操作系统都没有关系。它可以在JMeter可以运行的任何操作系统上运行。

7、提到JMeter中处理器的类型是什么？
　　JMeter中的处理器类型为：①预处理器；②后处理器。

8、解释什么是预置处理器元件？列出一些预处理器元件？
　　预置处理器是在采样器执行之前发生的事情。为了在执行采样请求之前对其进行配置，或者用于更新未从响应文本中提取的变量，需要使用预处理器元件。
一些预处理器元件是：

- HTTP URL重写修饰符
- HTTP用户参数修饰符
- HTML链接解析器
- BeanShell PreProcessor

9、是否提到测试元件的执行顺序？
　　测试计划元件的执行顺序为：
　　配置元件 -> 前置处理器 -> 计时器 -> 取样器 -> 后置处理器 -> 断言 -> 监听器

10、正则表达式中的“包含”和“匹配”表示什么？
　　在正则表达式中，contains表示正则表达式与目标的至少一部分匹配。匹配表示正则表达式匹配整个目标。如“alphabet”与“al.*t”匹配。

11、解释什么是配置元件？
　　配置元件与采样器并行工作。要设置默认值和变量以供采样器以后使用，可以使用配置元件。在合并范围的开始，将先处理这些元件，然后再处理同一合并范围中的任何采样器。

12、说明JMeter中的计时器是什么，计时器的类型是什么？
　　默认情况下，JMeter线程将连续发送请求而不会暂停。为了在请求之间暂停，使用了计时器。使用的一些计时器包括恒定计时器，高斯随机计时器，同步计时器，均匀随机计时器等。

13、解释什么是测试片段？
　　测试片段也是一种元件，例如“线程组”元件。唯一的区别是，除非模块控制器或包含控制器引用了测试片段，否则不会实现测试片段。

14、解释什么是JMeter中的断言？断言的类型有哪些？
　　断言有助于验证被测服务器是否返回了预期结果。
　　JMeter中一些常用的断言是：

- 响应断言
- 持续时间断言
- 大小断言（Size Assertion）
- XML断言
- HTML断言

15、说明如何减少JMeter中的资源需求？
　　①使用非GUI模式执行测试，如 jmeter –n –t test.jmx –l test.jtl
　　②在加载期间，测试不使用“查看结果树”或“查看表中的结果”监听器，仅在脚本编写阶段使用它们；
　　③不要使用功能模式；
　　④与其使用大量相似的采样器，不如在循环中使用相同的采样器，并使用变量来改变采样；

16、解释如何在JMeter中执行尖峰测试（Spike testing）？
　　通过同步，可以实现计时器JMeter尖峰测试。同步计时器将阻塞线程，直到阻塞了特定数量的线程，然后将它们全部释放，从而产生了巨大的瞬时负载。
小贴士：尖峰测试 也可以称为冲击测试，反复冲击服务器。指的是在某一瞬间或者多个频次下用户数和压力陡然增加的场景。

17、解释如何在JMeter中捕获身份验证窗口的脚本？
　　通常，可以通过录制来捕获脚本：
　　首先，必须在Testplan（测试计划）中使用 Threadgroup，然后在 Workbench（工作台） 中使用HTTP代理服务器；
　　之后，在“全局设置”框中设置端口号（如8911），然后在 IE高级选项>连接>局域网设置中 开启 代理设置，并将地址修改为localhost，端口改为8911。
然后，HTTP代理服务器中选择 目标控制器 Testplan>Threadgroup，然后启动HTTP代理服务器并运行应用进行登录。

18）列出几个JMeter监听器？
　　一些JMeter监听器是：

- 集合报告
- 汇总报告
- 查看结果树
- 用表格查看结果
- 图形结果
- BeanShell Listener
- 摘要报告等

19、什么是分布式负载测试？如何实现？
　　分布式负载测试是整个系统可以用来模拟大量用户负载的过程。通过使用主从配置，JMeter可以进行分布式负载测试。

20、在JMeter中是否有必要显式调用嵌入式资源？
　　你可以消除所有嵌入式资源的显式调用。请求底部有一个复选框，显示“检索嵌入式资源（retrieve embedded resources.）”。它会捕获所有CSS、JPG等。这是在Web应用中查找资源和断开链接的绝妙方法。

21、解释计时器（Timer）在JMeter中的作用是什么？
　　在计时器的帮助下，JMeter可以延迟线程发出的每个请求之间的时间。它可以解决服务器的过载问题。

22、解释什么是后置处理器？
　　要在发出请求后执行任何操作，则使用后处理器。例如，如果JMeter向Web服务器发送HTTP请求，并且如果你希望JMeter在Web服务器显示错误时停止发送请求，那么你将使用后处理器执行此操作。

23、JMeter为性能测试提供什么好处？
　　JMeter提供性能测试方面的优势，例如：

- - 它可以用于测试静态资源和动态资源的性能；
  - 它可用于测试网站最大并发用户数，从而分析定位网站瓶颈；
  - 它提供了性能报告的图形化分析；

### 消息中间件

什么是消息中间件？

​		面向消息的系统（消息中间件）是在分布式系统中完成消息的发送和接收的基础软件。消息中间件也可以称消息队列，是指用高效可靠的消息传递机制进行与平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息队列模型，可以在分布式环境下扩展进程的通信

​		消息中间件是基于队列与消息传递技术，在网络环境中为应用系统提供同步或异步、可靠的消息传输的支撑性软件系统

核心的有 3 个：**解耦**、**异步**、**削峰**。

#### 解耦

看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃......

 

![img](https://upload-images.jianshu.io/upload_images/10089464-bdc3230f73c148b6.png)

mq-1

在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！

如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。

 

![img](https://upload-images.jianshu.io/upload_images/10089464-57eb773f3dd4b53d.png)

mq-2

**总结**：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了。

**面试技巧**：你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。在简历中体现出来这块东西，用 MQ 作解耦。

#### 异步

再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。

 

![img](https://upload-images.jianshu.io/upload_images/10089464-c6a24c852cae87ba.png)

mq-3

一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都必须在 200 ms 以内完成，对用户几乎是无感知的。

如果**使用 MQ**，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！

 

![img](https://upload-images.jianshu.io/upload_images/10089464-11b4f57351c0f69d.png)

mq-4

#### 削峰

每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。

一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。

但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。



如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。

 

![img](https://upload-images.jianshu.io/upload_images/10089464-98c85c19e8f2f63d.png)



这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉。



## 进程间的八种通信方式

**1.无名管道( pipe )：** 管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

**2.高级管道(popen)：** 将另一个程序当做一个新的进程在当前程序进程中启动，则它算是当前程序的子进程，这种方式我们成为高级管道方式。

**3.有名管道 (named pipe) ：** 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

**4.消息队列( message queue ) ：** 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

**5.信号量( semophore ) ：** 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它**常作为一种锁机制**，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

**6.信号 ( sinal ) ：** 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

**7.共享内存( shared memory ) ：** 共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。

**8.套接字( socket ) ：** 套解字也是一种进程间通信机制，与其他通信机制不同的是，它**可用于不同机器间的进程通信**。



### 按通信类型区分

共享存储器系统
1.基于共享数据结构的通信方式
（仅适用于传递相对少量的数据，通信效率低，属于低级通信）
2.基于共享存储区的通信方式
管道通信系统
管道是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件（pipe文件）
管道机制需要提供一下几点的协调能力
	1.互斥，即当一个进程正在对pipe执行读/写操作时，其它进程必须等待
	2.同步，当一个进程将一定数量的数据写入，然后就去睡眠等待，直到读进程将数据取走，再去唤醒。读进程与之类似
	3.确定对方是否存在
消息传递系统
	1.直接通信方式
发送进程利用OS所提供的发送原语直接把消息发给目标进程
	2.间接通信方式
发送和接收进程都通过共享实体（邮箱）的方式进行消息的发送和接收
客户机服务器系统
	1.套接字 – 通信标识型的数据结构是进程通信和网络通信的基本构件
基于文件型的 （当通信进程都在同一台服务器中）其原理类似于管道
基于网络型的（非对称方式通信，发送者需要提供接收者命名。通信双方的进程运行在不同主机环境下被分配了一对套接字，一个属于发送进程，一个属于接收进程）
	2.远程过程调用和远程方法调用



##### 管道

管道，通常指无名管道，是 UNIX 系统IPC最古老的形式。

1、特点：
它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。

它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。

它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

管道分为pipe（无名管道）和fifo（命名管道）两种，除了建立、打开、删除的方式不同外，这两种管道几乎是一样的。他们都是通过内核缓冲区实现数据传输。

pipe用于相关进程之间的通信，例如父进程和子进程，它通过pipe()系统调用来创建并打开，当最后一个使用它的进程关闭对他的引用时，pipe将自动撤销。
FIFO即命名管道，在磁盘上有对应的节点，但没有数据块——换言之，只是拥有一个名字和相应的访问权限，通过mknode()系统调用或者mkfifo()函数来建立的。一旦建立，任何进程都可以通过文件名将其打开和进行读写，而不局限于父子进程，当然前提是进程对FIFO有适当的访问权。当不再被进程使用时，FIFO在内存中释放，但磁盘节点仍然存在。
管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据：管道一端的进程顺序地将进程数据写入缓冲区，另一端的进程则顺序地读取数据，该缓冲区可以看做一个循环队列，读和写的位置都是自动增加的，一个数据只能被读一次，读出以后再缓冲区都不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或写进程是否进入等待队列，当空的缓冲区有新数据写入或慢的缓冲区有数据读出时，就唤醒等待队列中的进程继续读写。



##### 3.2 无名管道

pipe的例子：父进程创建管道，并在管道中写入数据，而子进程从管道读出数据



##### 3.3 命名管道

和无名管道的主要区别在于，命名管道有一个名字，命名管道的名字对应于一个磁盘索引节点，有了这个文件名，任何进程有相应的权限都可以对它进行访问。

而无名管道却不同，进程只能访问自己或祖先创建的管道，而不能访任意访问已经存在的管道——因为没有名字。

Linux中通过系统调用mknod()或makefifo()来创建一个命名管道。最简单的方式是通过直接使用shell

mkfifo myfifo
1
等价于

mknod myfifo p
1
以上命令在当前目录下创建了一个名为myfifo的命名管道。用ls -p命令查看文件的类型时，可以看到命名管道对应的文件名后有一条竖线"|"，表示该文件不是普通文件而是命名管道。

使用open()函数通过文件名可以打开已经创建的命名管道，而无名管道不能由open来打开。当一个命名管道不再被任何进程打开时，它没有消失，还可以再次被打开，就像打开一个磁盘文件一样。

可以用删除普通文件的方法将其删除，实际删除的事磁盘上对应的节点信息。

例子：用命名管道实现聊天程序，一个张三端，一个李四端。两个程序都建立两个命名管道，fifo1,fifo2,张三写fifo1，李四读fifo1；李四写fifo2，张三读fifo2。

用select把，管道描述符和stdin假如集合，用select进行阻塞，如果有i/o的时候唤醒进程。（粉红色部分为select部分，黄色部分为命名管道部分）





##### 3.4 消息队列

消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。

消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。

可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。

消息队列的常用函数如下表：



进程间通过消息队列通信，主要是：创建或打开消息队列，添加消息，读取消息和控制消息队列。

##### 3.5 共享内存

共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出，从而实现了进程间的通信。

采用共享内存进行通信的一个主要好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝，对于像管道和消息队里等通信方式，则需要再内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次：一次从输入文件到共享内存区，另一次从共享内存到输出文件。



一般而言，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时在重新建立共享内存区域；而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件，因此，采用共享内存的通信方式效率非常高。



共享内存有两种实现方式：1、内存映射 2、共享内存机制

##### 3.6 信号量

信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

1、特点
信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

支持信号量组。

2、原型
最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二值信号量（Binary Semaphore）。而可以取多个正整数的信号量被称为通用信号量。

Linux 下的信号量函数都是在通用的信号量数组上进行操作，而不是在一个单一的二值信号量上进行操作。

```
#include <sys/sem.h>
// 创建或获取一个信号量组：若成功返回信号量集ID，失败返回-1
int semget(key_t key, int num_sems, int sem_flags);
// 对信号量组进行操作，改变信号量的值：成功返回0，失败返回-1
int semop(int semid, struct sembuf semoparray[], size_t numops);  
// 控制信号量的相关信息
int semctl(int semid, int sem_num, int cmd, ...);
```



### 消息队列有什么优缺点

优点上面已经说了，就是**在特殊场景下有其对应的好处**，**解耦**、**异步**、**削峰**。

缺点有以下几个：

- 系统可用性降低

  系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以[点击这里查看](https://www.cnblogs.com/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md)。

- 系统复杂度提高

  硬生生加个 MQ 进来，你怎么[保证消息没有重复消费]？怎么[处理消息丢失的情况]？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。

- 一致性问题

  A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。

所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。

#### 几种常见消息队列比较

Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点？

| 特性                     | ActiveMQ                              | RabbitMQ                                           | RocketMQ                                                     | Kafka                                                        |
| ------------------------ | ------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 单机吞吐量               | 万级，比 RocketMQ、Kafka 低一个数量级 | 同 ActiveMQ                                        | 10 万级，支撑高吞吐                                          | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响 |                                       |                                                    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                   | ms 级                                 | 微秒级，这是 RabbitMQ 的一大特点，延迟最低         | ms 级                                                        | 延迟在 ms 级以内                                             |
| 可用性                   | 高，基于主从架构实现高可用            | 同 ActiveMQ                                        | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性               | 有较低的概率丢失数据                  | 基本不丢                                           | 经过参数优化配置，可以做到 0 丢失                            | 同 RocketMQ                                                  |
| 功能支持                 | MQ 领域的功能极其完备                 | 基于 erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好                      | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |

综上，各种对比之后，有如下建议：

一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；

后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；

不过现在确实越来越多的公司，会去用 RocketMQ，确实很不错（阿里出品），但社区可能有突然黄掉的风险，对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。

所以**中小型公司**，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；**大型公司**，基础架构研发实力较强，用 RocketMQ 是很好的选择。如果是**大数据领域**的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。



### RabbitMQ简介

AMQP，即Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的[中间件](http://www.diggerplus.org/archives/tag/中间件)设计。消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。
AMQP的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全。
RabbitMQ是一个开源的AMQP实现，服务器端用**Erlang**语言编写，支持多种客户端，如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP等，支持AJAX。用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。
下面将重点介绍RabbitMQ中的一些基础概念，了解了这些概念，是使用好RabbitMQ的基础。

#### **ConnectionFactory、Connection、Channel**

ConnectionFactory、Connection、Channel都是RabbitMQ对外提供的API中最基本的对象。Connection是RabbitMQ的socket链接，它封装了socket协议相关部分逻辑。ConnectionFactory为Connection的制造工厂。
Channel是我们与RabbitMQ打交道的最重要的一个接口，我们大部分的业务操作是在Channel这个接口中完成的，包括定义Queue、定义Exchange、绑定Queue与Exchange、发布消息等。

#### Queue

Queue（队列）是RabbitMQ的内部对象，用于存储消息，用下图表示。
![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819103814085-804287529.png)

RabbitMQ中的消息都只能存储在Queue中，生产者（下图中的P）生产消息并最终投递到Queue中，消费者（下图中的C）可以从Queue中获取消息并消费。

![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819103830954-867723738.png)

多个消费者可以订阅同一个Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。



#### Message acknowledgment

在实际应用中，可能会发生消费者收到Queue中的消息，但没有处理完成就宕机（或出现其他意外）的情况，这种情况下就可能会导致消息丢失。为了避免这种情况发生，我们可以要求消费者在消费完消息后发送一个回执给RabbitMQ，RabbitMQ收到消息回执（Message acknowledgment）后才将该消息从Queue中移除；如果RabbitMQ没有收到回执并检测到消费者的RabbitMQ连接断开，则RabbitMQ会将该消息发送给其他消费者（如果存在多个消费者）进行处理。这里不存在timeout概念，一个消费者处理消息时间再长也不会导致该消息被发送给其他消费者，除非它的RabbitMQ连接断开。
这里会产生另外一个问题，如果我们的开发人员在处理完业务逻辑后，忘记发送回执给RabbitMQ，这将会导致严重的bug——Queue中堆积的消息会越来越多；消费者重启后会重复消费这些消息并重复执行业务逻辑…

#### Message durability

如果我们希望即使在RabbitMQ服务重启的情况下，也不会丢失消息，我们可以将Queue与Message都设置为可持久化的（durable），这样可以保证绝大部分情况下我们的RabbitMQ消息不会丢失。但依然解决不了小概率丢失事件的发生（比如RabbitMQ服务器已经接收到生产者的消息，但还没来得及持久化该消息时RabbitMQ服务器就断电了），如果我们需要对这种小概率事件也要管理起来，那么我们要用到事务。由于这里仅为RabbitMQ的简单介绍，所以这里将不讲解RabbitMQ相关的事务。

#### Prefetch count

前面我们讲到如果有多个消费者同时订阅同一个Queue中的消息，Queue中的消息会被平摊给多个消费者。这时如果每个消息的处理时间不同，就有可能会导致某些消费者一直在忙，而另外一些消费者很快就处理完手头工作并一直空闲的情况。我们可以通过设置prefetchCount来限制Queue每次发送给每个消费者的消息数，比如我们设置prefetchCount=1，则Queue每次给每个消费者发送一条消息；消费者处理完这条消息后Queue会再给该消费者发送一条消息。

![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819104007647-1027286628.png)

#### Exchange

在上一节我们看到生产者将消息投递到Queue中，实际上这在RabbitMQ中这种事情永远都不会发生。实际的情况是，生产者将消息发送到Exchange（交换器，下图中的X），由Exchange将消息路由到一个或多个Queue中（或者丢弃）。

![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819104028789-412276700.png)

Exchange是按照什么逻辑将消息路由到Queue的？这个将在Binding一节介绍。
RabbitMQ中的Exchange有四种类型，不同的类型有着不同的路由策略，这将在Exchange Types一节介绍。

#### routing key

生产者在将消息发送给Exchange的时候，一般会指定一个routing key，来指定这个消息的路由规则，而这个routing key需要与Exchange Type及binding key联合使用才能最终生效。
在Exchange Type与binding key固定的情况下（在正常使用时一般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过指定routing key来决定消息流向哪里。
RabbitMQ为routing key设定的长度限制为255 bytes。

#### Binding

RabbitMQ中通过Binding将Exchange与Queue关联起来，这样RabbitMQ就知道如何正确地将消息路由到指定的Queue了。
![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819104128931-1338459538.png)

 

#### Binding key

在绑定（Binding）Exchange与Queue的同时，一般会指定一个binding key；消费者将消息发送给Exchange时，一般会指定一个routing key；当binding key与routing key相匹配时，消息将会被路由到对应的Queue中。这个将在Exchange Types章节会列举实际的例子加以说明。
在绑定多个Queue到同一个Exchange的时候，这些Binding允许使用相同的binding key。
binding key 并不是在所有情况下都生效，它依赖于Exchange Type，比如fanout类型的Exchange就会无视binding key，而是将消息路由到所有绑定到该Exchange的Queue。

#### Exchange Types

RabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种（AMQP规范里还提到两种Exchange Type，分别为system与自定义，这里不予以描述），下面分别进行介绍。

#### fanout

fanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。
![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819104152177-2053988251.png)

 

上图中，生产者（P）发送到Exchange（X）的所有消息都会路由到图中的两个Queue，并最终被两个消费者（C1与C2）消费。

#### direct

direct类型的Exchange路由规则也很简单，它会把消息路由到那些binding key与routing key完全匹配的Queue中。



![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819104210818-1771762193.png)

 

以上图的配置为例，我们以routingKey=”error”发送消息到Exchange，则消息会路由到Queue1（amqp.gen-S9b…，这是由RabbitMQ自动生成的Queue名称）和Queue2（amqp.gen-Agl…）；如果我们以routingKey=”info”或routingKey=”warning”来发送消息，则消息只会路由到Queue2。如果我们以其他routingKey发送消息，则消息不会路由到这两个Queue中。

#### topic

前面讲到direct类型的Exchange路由规则是完全匹配binding key与routing key，但这种严格的匹配方式在很多情况下不能满足实际业务需求。topic类型的Exchange在匹配规则上进行了扩展，它与direct类型的Exchage相似，也是将消息路由到binding key与routing key相匹配的Queue中，但这里的匹配规则有些不同，它约定：

- routing key为一个句点号“. ”分隔的字符串（我们将被句点号“. ”分隔开的每一段独立的字符串称为一个单词），如“stock.usd.nyse”、“nyse.vmw”、“quick.orange.rabbit”
- binding key与routing key一样也是句点号“. ”分隔的字符串
- binding key中可以存在两种特殊字符“*”与“#”，用于做模糊匹配，其中“*”用于匹配一个单词，“#”用于匹配多个单词（可以是零个）

 

![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819104233644-253637000.png)

 

以上图中的配置为例，routingKey=”quick.orange.rabbit”的消息会同时路由到Q1与Q2，routingKey=”lazy.orange.fox”的消息会路由到Q1，routingKey=”lazy.brown.fox”的消息会路由到Q2，routingKey=”lazy.pink.rabbit”的消息会路由到Q2（只会投递给Q2一次，虽然这个routingKey与Q2的两个bindingKey都匹配）；routingKey=”quick.brown.fox”、routingKey=”orange”、routingKey=”quick.orange.male.rabbit”的消息将会被丢弃，因为它们没有匹配任何bindingKey。

#### headers

headers类型的Exchange不依赖于routing key与binding key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。
在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对；如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。
该类型的Exchange没有用到过（不过也应该很有用武之地），所以不做介绍。

#### RPC

MQ本身是基于异步的消息处理，前面的示例中所有的生产者（P）将消息发送到RabbitMQ后不会知道消费者（C）处理成功或者失败（甚至连有没有消费者来处理这条消息都不知道）。
但实际的应用场景中，我们很可能需要一些同步处理，需要同步等待服务端将我的消息处理完成后再进行下一步处理。这相当于RPC（Remote Procedure Call，远程过程调用）。在RabbitMQ中也支持RPC。

![img](https://img2018.cnblogs.com/blog/774371/201908/774371-20190819104253450-1490098886.png)

 


RabbitMQ中实现RPC的机制是：

- 客户端发送请求（消息）时，在消息的属性（MessageProperties，在AMQP协议中定义了14中properties，这些属性会随着消息一起发送）中设置两个值replyTo（一个Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue中）和correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败）
- 服务器端收到消息并处理
- 服务器端处理完消息后，将生成一条应答消息到replyTo指定的Queue，同时带上correlationId属性
- 客户端之前已订阅replyTo指定的Queue，从中收到服务器的应答消息后，根据其中的correlationId属性分析哪条请求被执行了，根据执行结果进行后续业务处理



## **Redis**



Redis是一个开源的使用ANSI **C语言**编写、支持网络、可基于内存亦可持久化的日志型、**Key-Value数据库**，并提供多种语言的API

**Redis是单线程**

redis利用队列技术将并发访问变为串行访问，消除了传统数据库串行控制的开销

**Reids常用5种数据类型**

string，list，set，sorted set，hash



**Redis特点**

Redis以内存作为数据存储介质，读写数据的效率极高。

Redis跟memcache不同的是，储存在Redis中的数据是持久化的，断电或重启，数据也不会丢失。

Redis的存储分为内存存储、磁盘存储和log文件。

Redis可以从磁盘重新将数据加载到内存中，也可以通过配置文件对其进行配置，因此，redis才能实现持久化。

Redis支持主从模式，可以配置集群，更利于支撑大型的项目。



**Redis应用场景**

​     众多语言都支持Redis，因为Redis交换数据快，在服务器中常用来存储一些需要频繁调取的数据，节省内存开销，也极大的提升了速度。

​    将一些热点数据存储到Redis中，要用的时候，直接从内存取，极大的提高了速度和节约了服务器的开销。

​    1、会话缓存（最常用） 

​    2、消息队列（支付）

​    3、活动排行榜或计数

​    4、发布，订阅消息（消息通知）

​    5、商品列表，评论列表



**Reids6种淘汰策略：**

- **noeviction**: 不删除策略, 达到最大内存限制时, 如果需要更多内存, 直接返回错误信息。大多数写命令都会导致占用更多的内存(有极少数会例外。
- **allkeys-lru:**所有key通用; 优先删除最近最少使用(less recently used ,LRU) 的 key。
- **volatile-lru:**只限于设置了 expire 的部分; 优先删除最近最少使用(less recently used ,LRU) 的 key。
- **allkeys-random:**所有key通用; 随机删除一部分 key。
- **volatile-random**: 只限于设置了 **expire** 的部分; 随机删除一部分 key。
- **volatile-ttl**: 只限于设置了 **expire** 的部分; 优先删除剩余时间(time to live,TTL) 短的key。
- 

**Redis 有哪些架构模式**

**单机版**

![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142100480-1152515615.png)

特点：简单

问题：

1、内存容量有限 2、处理能力有限 3、无法高可用。

**主从复制**

**![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142118041-1727225479.png)**

Redis 的复制（replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（master），而通过复制创建出来的服务器复制品则为从服务器（slave）。 只要主从服务器之间的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步 给从服务器，从而一直保证主从服务器的数据相同



特点：

1、master/slave 角色

2、master/slave 数据相同

3、降低 master 读压力在转交从库

问题：

无法保证高可用

没有解决 master 写的压力



**哨兵**

**![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142143478-1454265814.png)**

Redis sentinel 是一个分布式系统中监控 redis 主从服务器，并在主服务器下线时自动进行故障转移。其中三个特性：

监控（Monitoring）：  Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。

提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。

自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。

特点：

1、保证高可用

2、监控各个节点

3、自动故障迁移

缺点：主从模式，切换需要时间丢数据

没有解决 master 写的压力

**集群（proxy 型）：**

**![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142206124-913246424.png)**

Twemproxy 是一个 Twitter 开源的一个 redis 和 memcache 快速/轻量级代理服务器； Twemproxy 是一个快速的单线程代理程序，支持 Memcached ASCII 协议和 redis 协议。

特点：1、多种 hash 算法：MD5、CRC16、CRC32、CRC32a、hsieh、murmur、Jenkins 

2、支持失败节点自动删除

3、后端 Sharding 分片逻辑对业务透明，业务方的读写方式和操作单个 Redis 一致

缺点：增加了新的 proxy，需要维护其高可用。

 

failover 逻辑需要自己实现，其本身不能支持故障的自动转移可扩展性差，进行扩缩容都需要手动干预

**集群（直连型）：**

**![img](https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925142304757-1498788186.png)**

从redis 3.0之后版本支持redis-cluster集群，Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。

特点：

1、无中心架构（不存在哪个节点影响性能瓶颈），少了 proxy 层。

2、数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。

3、可扩展性，可线性扩展到 1000 个节点，节点可动态添加或删除。

4、高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做备份数据副本

5、实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave到 Master 的角色提升。

缺点：

1、资源隔离性较差，容易出现相互影响的情况。

2、数据通过异步复制,不保证数据的强一致性





### 缓存与数据库不一致

##### 基础顺序：

读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应

更新的时候，先更新数据库，然后再删除缓存。

**为什么是删除缓存，而不是更新缓存？**

频繁更新缓存代价较高，且无法确定该缓存的被访问次数，较低则会产生大量冷数据。实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。**用到缓存才去算缓存。**

其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，**而是让它到需要被使用的时候再重新计算**。像 mybatis，hibernate，都有懒加载思想。查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都里面的 1000 个员工的数据也同时查出来啊。80% 的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。

##### 产生环境

**最初级的缓存不一致问题以及解决方案**
问题：先修改数据库，再删除缓存，如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致。
解决思路：
　　先删除缓存，再修改数据库，如果删除缓存成功了修改数据库失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致，因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中。

　　![img](https://img2018.cnblogs.com/blog/1363214/201909/1363214-20190928104103320-652143063.png)

**2、并发下数据缓存不一致问题分析**
问题：
　　第一个请求数据发生变更，先删除了缓存，然后要去修改数据库，此时还没来得及去修改；
　　第二个请求过来去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中（脏读）；
　　第三个请求读取缓存中的数据 (此时第一个请求已经完成了数据库修改的操作)。

​		如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况

问题分析：
　　只有在对同一条数据并发读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就1万次，那么很少的情况下，会出现刚才描述的那种不一致的场景;但如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况。
解决思路
　　数据库的缓存更新与读取操作进行串行化，一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。
　　1. 首先我们的项目里维护一组线程池和内存队列。
　　2. 更新数据的时候，根据数据的唯一标识将请求路由到一个jvm队列中，去更新数据库,然后请求结束。
　　3. 读取数据的时候，先查缓存，如果发现数据不在缓存中，那么将根据唯一标识路由之后，也发送同一个jvm内部的队列中，重新读取数据库后更新缓存,最后请求结束。

　　 <img src="https://img2018.cnblogs.com/blog/1363214/201909/1363214-20190929191217957-1916614649.png" alt="img" style="zoom:40%;" />

　　这里有一个需要优化的点，比如一个队列中，连续存在多个更新缓存请求串在一起是没意义的，这样重复的查询数据库并更新缓存的操作应该优化：如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接让后面的读请求阻塞个200ms左右(这里只是举个例子，实际值可以根据服务的响应时间和机器的处理能力来计算)，然后再次查询缓存，如果缓存没有值就查数据库，拿到结果后不用更新缓存，直接返回给页面即可。



##### **延时双删策略+缓存超时设置**

- 在**写库前后都进行删除缓存操作（**redis.del(key)**）**，并且**设定合理的缓存过期时间**。**具体的步骤就是：**

1. 先删除缓存；
2. 再写数据库；
3. 休眠一段时间；
4. 再次删除缓存。

- **设置缓存过期时间**

​    所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值，然后再回填缓存。

### 缓存穿透、缓存击穿、缓存雪崩区别和解决方案

一、缓存处理流程

  前台请求，后台先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果。


​      

二、缓存穿透

   描述：

   缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。

  解决方案：

接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击


三、缓存击穿

  描述：

  缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力

  解决方案：

设置热点数据永远不过期。
加互斥锁，互斥锁参考代码如下：
         

 

​      说明：

​      1）缓存中有数据，直接走上述代码13行后就返回结果了

​     2）缓存中没有数据，第1个进入的线程，获取锁并从数据库去取数据，没释放锁之前，其他并行进入的线程会等待100ms，再重新去缓存取数据。这样就防止都去数据库重复取数据，重复往缓存中更新数据情况出现。

​      3）当然这是简化处理，理论上如果能根据key值加锁就更好了，就是线程A从数据库取key1的数据并不妨碍线程B取key2的数据，上面代码明显做不到这点。

 


四、缓存雪崩

  描述：

  缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是，        缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

 解决方案：

缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
设置热点数据永远不过期。





## 实际策略





![图片](https://mmbiz.qpic.cn/mmbiz_png/qm3R3LeH8raYmr3dsqIWbpw1JJguysYX496pf9Ihz5thAYNNfe3V89rmVyicQa67PNeGxaUXWdR8C8XK4pTVruQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 防止超卖

为了解决上面的超卖问题，我们当然可以在Service层给更新表添加一个事务，这样每个线程更新请求的时候都会先去锁表的这一行（悲观锁），更新完库存后再释放锁。可这样就太慢了，1000个线程可等不及。

我们需要乐观锁。

一个最简单的办法就是，给每个商品库存一个版本号version字段

我们在实际减库存的SQL操作中，首先判断version是否是我们查询库存时候的version，如果是，扣减库存，成功抢购。如果发现version变了，则不更新数据库，返回抢购失败。

令牌桶限流

Guava是Google开源的Java工具类，里面包罗万象，也提供了限流工具类RateLimiter，该类里面实现了令牌桶算法

代码中，`RateLimiter rateLimiter = RateLimiter.create(10);`这里初始化了令牌桶类，每秒放行10个请求。

在接口中，可以看到有两种使用方法：

- 阻塞式获取令牌：请求进来后，若令牌桶里没有足够的令牌，就在这里阻塞住，等待令牌的发放。
- 非阻塞式获取令牌：请求进来后，若令牌桶里没有足够的令牌，会尝试等待设置好的时间（这里写了1000ms），其会自动判断在1000ms后，这个请求能不能拿到令牌，如果不能拿到，直接返回抢购失败。如果timeout设置为0，则等于阻塞时获取令牌。

我们使用JMeter设置200个线程，来同时抢购数据库里库存100个的iphone。（数据库结构和JMeter使用请查看从零开始搭建简易秒杀系统（一）：防止超卖）



- 乐观锁比较适合数据修改比较少，读取比较频繁的场景，即使出现了少量的冲突，这样也省去了大量的锁的开销，故而提高了系统的吞吐量。
- 但是如果经常发生冲突（写数据比较多的情况下），上层应用不不断的retry，这样反而降低了性能，对于这种情况使用悲观锁就更合适

所以，悲观锁在大量请求的请求下，有着更好的卖出成功率。但是需要注意的是，如果请求量巨大，悲观锁会导致后面的请求进行了长时间的阻塞等待，用户就必须在页面等待，很像是“假死”，可以通过配合令牌桶限流，或者是给用户显著的等待提示来优化



所以我们需要将抢购接口进行隐藏，**抢购接口隐藏（接口加盐）的具体做法**：

- 每次点击秒杀按钮，先从服务器获取一个秒杀验证值（接口内判断是否到秒杀时间）。
- Redis以缓存用户ID和商品ID为Key，秒杀地址为Value缓存验证值
- 用户请求秒杀商品的时候，要带上秒杀验证值进行校验。

#### 单用户限制频率

假设我们做好了接口隐藏，但是像我上面说的，总有无聊的人会写一个复杂的脚本，先请求hash值，再立刻请求购买，如果你的app下单按钮做的很差，大家都要开抢后0.5秒才能请求成功，那可能会让脚本依然能够在大家前面抢购成功。

我们需要在做一个额外的措施，来限制单个用户的抢购频率。

其实很简单的就能想到用redis给每个用户做访问统计，甚至是带上商品id，对单个商品做访问统计，这都是可行的。

我们先实现一个对用户的访问频率限制，我们在用户申请下单时，检查用户的访问次数，超过访问次数，则不让他下单！



UserService中增加两个方法：

- addUserCount：每当访问订单接口，则增加一次访问次数，写入Redis
- getUserIsBanned：从Redis读出该用户的访问次数，超过10次则不让购买了！不能让张三做法外狂徒

#### **缓存和数据库双写一致性**



#### 订单异步处理

真正的下单的操作流程为：

- 校验数据库库存
- 乐观锁更新库存（其他之前讲到的锁也可以啦）
- 写入订单至数据库
- **「写入订单和用户信息至缓存供查询」**：写入后，在外层接口便可以通过判断redis中是否存在用户和商品的抢购信息，来直接给用户返回“你已经抢购过”的消息。

**「我是如何在redis中记录商品和用户的关系的呢，我使用了set集合，key是商品id，而value则是用户id的集合，当然这样有一些不合理之处：」**

- 这种结构默认了一个用户只能抢购一次这个商品
- 使用set集合，在用户过多后，每次检查需要遍历set，用户过多有性能问题



那么问题来了，我们实现了上面的异步处理后，用户那边得到的结果是怎么样的呢？

用户点击了提交订单，收到了消息：您的订单已经提交成功。然后用户啥也没看见，也没有订单号，用户开始慌了，点到了自己的个人中心——已付款。发现居然没有订单！（因为可能还在队列中处理）

这样的话，用户可能马上就要开始投诉了！太不人性化了，我们不能只为了开发方便，舍弃了用户体验！

所以我们要改进一下，如何改进呢？其实很简单：

- 让前端在提交订单后，显示一个“排队中”，**「就像我们在小米官网抢小米手机那样」**
- 同时，前端不断请求 检查用户和商品是否已经有订单 的接口，如果得到订单已经处理完成的消息，页面跳转抢购成功



#### 阿里开源MySQL中间件Canal快速入门

**「Canal用途很广，并且上手非常简单，小伙伴们在平时完成公司的需求时，很有可能会用到。」**

举个例子：

公司目前有多个开发人员正在开发一套服务，为了缩短调用延时，对部分接口数据加入了缓存。一旦这些数据在数据库中进行了更新操作，缓存就成了旧数据，必须及时删除。

删除缓存的代码**「理所当然可以写在更新数据的业务代码里」**，但有时候者写操作是在别的项目代码里，你可能无权修改，亦或者别人不愿你在他代码里写这种业务之外的代码。（毕竟多人协作中间会产生各种配合问题）。又或者就是单纯的删除缓存的操作失败了，缓存依然是旧数据。

**本篇文章的要点如下：」**

- Canal是什么

- Canal工作原理

- 数据库的读写分离

- 数据库主从同步

- 数据库主从同步一致性问题

- - 异步复制
  - 全同步复制
  - 半同步复制

- Canal实战

- - 开启MySQL Binlog
  - 配置Canal服务
  - 运行Canal服务
  - Java客户端Demo

- 

众所周知，阿里是国内比较早地大量使用MySQL的互联网企业（去IOE化：去掉IBM的小型机、Oracle数据库、EMC存储设备，代之以自己在开源软件基础上开发的系统），并且基于阿里巴巴/淘宝的业务，从 2010 年开始，业务逐步尝试数据库日志解析获取增量变更进行同步，由此衍生出了大量的数据库增量订阅和消费业务。

Canal应运而生，它通过伪装成数据库的从库，读取主库发来的binlog，用来实现**「数据库增量订阅和消费业务需求」**。

**「Canal用途：」**

- 数据库镜像
- 数据库实时备份
- 索引构建和实时维护(拆分异构索引、倒排索引等)
- **「业务 cache 缓存刷新」**
- 带业务逻辑的增量数据处理

Canal重要特点

- canal 使用 client-server 模式，数据传输协议使用 protobuf 3.0（很多RPC框架也在使用例如gRPC）
- 当前的 canal 支持源端 MySQL 版本包括 5.1.x , 5.5.x , 5.6.x , 5.7.x , 8.0.x
- canal 作为 MySQL binlog 增量获取和解析工具，可将变更记录投递到 MQ 系统中，比如 Kafka/RocketMQ。



Canal实际是将自己伪装成数据库的从库，来读取Binlog

### 数据库的读写分离

为了应对高并发场景，MySQL支持把一台数据库主机分为单独的一台写主库（主要负责写操作），而把读的数据库压力分配给读的从库，而且读从库可以变为多台，这就是读写分离的典型场景。

![图片](https://mmbiz.qpic.cn/mmbiz_png/qm3R3LeH8rbhJVj76bEZezSEkv6UwCzSawPUBzI0HwbZFLVYyQOjoayt3HEYsricC04XR72Kzq5icDn1KqUflqJg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

### 数据库主从同步

实现数据库的读写分离，是通过数据库主从同步，让从数据库监听主数据库Binlog实现的。大体流程如下图：

> ❝
>
> MySQL master 将数据变更写入二进制日志( binary log, 其中记录叫做二进制日志事件binary log events，可以通过 show binlog events 进行查看)
>
> MySQL slave 将 master 的 binary log events 拷贝到它的中继日志(relay log)
>
> MySQL slave 重放 relay log 中事件，将数据变更反映它自己的数据
>
> ❞

![图片](https://mmbiz.qpic.cn/mmbiz_png/qm3R3LeH8rbhJVj76bEZezSEkv6UwCzSdjqOJxMqWM7D6U5aTic3yhgsLXN2ZD6FFJlGV4JG8wib77O8ibHXEYWdg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

详细主从同步原理在这里就不展开细说了。

可以看到，这种架构下会有一个问题，**「数据库主从同步会存在延迟，那么就会有短暂的时间，主从数据库的数据是不一致的。」**

这种不一致大多数情况下非常短暂，很多时候我们可以忽略他。

但一旦要求数据一致，就会引申出如何解决这个问题的思考。

### 数据库主从同步一致性问题

我们通常使用MySQL主从复制来解决MySQL的单点故障问题，其通过逻辑复制的方式把主库的变更同步到从库，主备之间无法保证严格一致的模式，

于是，MySQL的主从复制带来了主从“数据一致性”的问题。**「MySQL的复制分为：异步复制、半同步复制、全同步复制。」**

#### 异步复制

MySQL默认的复制即是异步复制，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，**「主如果crash掉了，此时主上已经提交的事务可能并没有传到从库上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。」**

> ❝
>
> 主库将事务 Binlog 事件写入到 Binlog 文件中，此时主库只会通知一下 Dump 线程发送这些新的 Binlog，然后主库就会继续处理提交操作，而此时不会保证这些 Binlog 传到任何一个从库节点上。
>
> ❞

#### 全同步复制

指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。**「因为需要等待所有从库执行完该事务才能返回」**，所以全同步复制的性能必然会收到严重的影响。

> ❝
>
> 当主库提交事务之后，所有的从库节点必须收到、APPLY并且提交这些事务，然后主库线程才能继续做后续操作。但缺点是，主库完成一个事务的时间会被拉长，性能降低。
>
> ❞

#### 半同步复制

是介于全同步复制与全异步复制之间的一种，**「主库只需要等待至少一个从库节点收到」**并且 Flush Binlog 到 Relay Log 文件即可，主库不需要等待所有从库给主库反馈。同时，**「这里只是一个收到的反馈，而不是已经完全完成并且提交的反馈」**，如此，节省了很多时间。

> ❝
>
> 介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，**「同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。」**
>
> ❞

![图片](https://mmbiz.qpic.cn/mmbiz_png/qm3R3LeH8rbhJVj76bEZezSEkv6UwCzSTO0thpicqKZx8neic53Js0y8ykHP7mpickBRBBIEw71w8e7dl4icVs056g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

**「事实上，半同步复制并不是严格意义上的半同步复制，MySQL半同步复制架构中，主库在等待备库ack时候，如果超时会退化为异步后，也可能导致“数据不一致”。」**

> ❝
>
> 当半同步复制发生超时时（由rpl_semi_sync_master_timeout参数控制，单位是毫秒，默认为10000，即10s），会暂时关闭半同步复制，转而使用异步复制。当master dump线程发送完一个事务的所有事件之后，如果在rpl_semi_sync_master_timeout内，收到了从库的响应，则主从又重新恢复为半同步复制。
>
> ❞

关于半同步复制的详细原理分析可以看这篇引申文章，在此不展开：

https://www.cnblogs.com/ivictor/p/5735580.html

### 回到Canal的工作原理

回顾了数据库从库的数据同步原理，理解Canal十分简单，直接引用官网原文：

- canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议
- MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )
- canal 解析 binary log 对象(原始为 byte 流)

##  